{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "toc_visible": true
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Actuarial Pricing Process Automation\n",
                "## End-to-End Insurance Claims Cost Prediction\n",
                "\n",
                "### Objective\n",
                "Demonstrate actuarial pricing automation with decision intervention points at each stage.\n",
                "\n",
                "### Process Overview\n",
                "1. Data Collection\n",
                "2. Data Cleaning\n",
                "3. Exploratory Data Analysis\n",
                "4. Loss Estimation\n",
                "5. Risk Factor Analysis\n",
                "6. Premium Calculation\n",
                "7. Final Pricing\n",
                "8. Output Generation & Submission"
            ],
            "metadata": {
                "id": "intro"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Stage 0: Environment Setup"
            ],
            "metadata": {
                "id": "stage0"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "!pip install -q xgboost lightgbm catboost kaggle"
            ],
            "metadata": {
                "id": "install"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import os\n",
                "from sklearn.model_selection import KFold\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.metrics import mean_absolute_error\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "import xgboost as xgb\n",
                "import lightgbm as lgb\n",
                "from catboost import CatBoostRegressor\n",
                "\n",
                "print('Libraries loaded')"
            ],
            "metadata": {
                "id": "imports"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "---\n",
                "## Stage 1: Data Collection\n",
                "\n",
                "**Decision Points:**\n",
                "- Time period for analysis\n",
                "- External data requirements\n",
                "- Data granularity level\n",
                "\n",
                "---\n",
                "**Egyptian UHI Context:**\n",
                "\n",
                "Per Law 2/2018, Article 44, actuarial review must be conducted every 4 years."
            ],
            "metadata": {
                "id": "stage1"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 1: Upload kaggle.json file\n",
                "from google.colab import files\n",
                "print('Please upload your kaggle.json file:')\n",
                "uploaded = files.upload()"
            ],
            "metadata": {
                "id": "upload_kaggle"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 2: Setup Kaggle credentials\n",
                "!mkdir -p ~/.kaggle\n",
                "!cp kaggle.json ~/.kaggle/\n",
                "!chmod 600 ~/.kaggle/kaggle.json\n",
                "print('Kaggle credentials configured.')"
            ],
            "metadata": {
                "id": "setup_kaggle"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 3: Download competition data\n",
                "# Competition: actuarial-loss-estimation\n",
                "\n",
                "COMPETITION = 'actuarial-loss-estimation'\n",
                "\n",
                "print(f'Downloading data from {COMPETITION}...')\n",
                "!kaggle competitions download -c {COMPETITION}\n",
                "\n",
                "# Extract\n",
                "import glob\n",
                "zip_files = glob.glob('*.zip')\n",
                "if zip_files:\n",
                "    print(f'Found: {zip_files}')\n",
                "    !unzip -q -o {COMPETITION}.zip\n",
                "    print('Data extracted successfully!')\n",
                "else:\n",
                "    print('ERROR: Download failed. Please accept competition rules at:')\n",
                "    print(f'https://www.kaggle.com/competitions/{COMPETITION}')"
            ],
            "metadata": {
                "id": "download_data"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Load data\n",
                "train = pd.read_csv('train.csv')\n",
                "test = pd.read_csv('test.csv')\n",
                "print(f'Training data: {train.shape}')\n",
                "print(f'Test data: {test.shape}')\n",
                "train.head()"
            ],
            "metadata": {
                "id": "load_data"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "---\n",
                "## Stage 2: Data Cleaning\n",
                "\n",
                "**Decision Points:**\n",
                "- Missing value imputation method\n",
                "- Outlier treatment approach\n",
                "- Data quality thresholds"
            ],
            "metadata": {
                "id": "stage2"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "print('Data Quality Report')\n",
                "print(f'Total records: {len(train):,}')\n",
                "missing = train.isnull().sum()\n",
                "missing_pct = (missing / len(train) * 100).round(2)\n",
                "missing_report = pd.DataFrame({'Missing': missing, 'Pct': missing_pct})\n",
                "print(missing_report[missing_report['Missing'] > 0])"
            ],
            "metadata": {
                "id": "data_quality"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# ACTUARY DECISION: Missing Value Strategy\n",
                "MISSING_STRATEGY = {\n",
                "    'numeric': 'median',\n",
                "    'categorical': 'mode',\n",
                "    'threshold_drop': 0.5\n",
                "}\n",
                "\n",
                "def clean_data(df, config):\n",
                "    df = df.copy()\n",
                "    for col in df.select_dtypes(include=[np.number]).columns:\n",
                "        if df[col].isnull().any():\n",
                "            df[col] = df[col].fillna(df[col].median())\n",
                "    for col in df.select_dtypes(include=['object']).columns:\n",
                "        if df[col].isnull().any():\n",
                "            df[col] = df[col].fillna('MISSING')\n",
                "    return df\n",
                "\n",
                "train_clean = clean_data(train, MISSING_STRATEGY)\n",
                "test_clean = clean_data(test, MISSING_STRATEGY)\n",
                "print('Data cleaned')"
            ],
            "metadata": {
                "id": "clean_data"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "---\n",
                "## Stage 3: Exploratory Data Analysis\n",
                "\n",
                "**Decision Points:**\n",
                "- Target distribution transformation\n",
                "- Key predictive variables"
            ],
            "metadata": {
                "id": "stage3"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "TARGET = 'UltimateIncurredClaimCost'\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "axes[0].hist(train_clean[TARGET], bins=50, color='steelblue', edgecolor='white')\n",
                "axes[0].set_title('Original Distribution')\n",
                "axes[1].hist(np.log1p(train_clean[TARGET]), bins=50, color='coral', edgecolor='white')\n",
                "axes[1].set_title('Log Transformed')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ],
            "metadata": {
                "id": "eda_target"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# ACTUARY DECISION: Target Transformation\n",
                "TARGET_TRANSFORM = 'log'\n",
                "print(f'Selected transformation: {TARGET_TRANSFORM}')\n",
                "\n",
                "if TARGET_TRANSFORM == 'log':\n",
                "    y = np.log1p(train_clean[TARGET])\n",
                "else:\n",
                "    y = train_clean[TARGET]"
            ],
            "metadata": {
                "id": "target_transform"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "---\n",
                "## Stage 4: Loss Estimation\n",
                "\n",
                "**Decision Points:**\n",
                "- Model selection\n",
                "- Hyperparameters\n",
                "- Validation approach"
            ],
            "metadata": {
                "id": "stage4"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "EXCLUDE_COLS = [TARGET, 'ClaimNumber', 'ClaimDescription', 'AccidentDescription',\n",
                "                'DateTimeOfAccident', 'DateReported', 'DateOfBirth']\n",
                "\n",
                "feature_cols = [c for c in train_clean.columns if c not in EXCLUDE_COLS]\n",
                "\n",
                "for col in train_clean[feature_cols].select_dtypes(include=['object']).columns:\n",
                "    le = LabelEncoder()\n",
                "    all_vals = pd.concat([train_clean[col], test_clean[col]]).astype(str).unique()\n",
                "    le.fit(all_vals)\n",
                "    train_clean[col] = le.transform(train_clean[col].astype(str))\n",
                "    test_clean[col] = le.transform(test_clean[col].astype(str))\n",
                "\n",
                "X = train_clean[feature_cols].fillna(-999)\n",
                "X_test = test_clean[feature_cols].fillna(-999)\n",
                "print(f'Features prepared: {len(feature_cols)}')"
            ],
            "metadata": {
                "id": "prepare_features"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# ACTUARY DECISION: Model Configuration\n",
                "MODEL_CONFIG = {\n",
                "    'models': ['xgboost', 'lightgbm', 'catboost'],\n",
                "    'n_folds': 5,\n",
                "    'ensemble_method': 'average'\n",
                "}\n",
                "\n",
                "print('Model Configuration:')\n",
                "for k, v in MODEL_CONFIG.items():\n",
                "    print(f'  {k}: {v}')"
            ],
            "metadata": {
                "id": "model_config"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "kf = KFold(n_splits=MODEL_CONFIG['n_folds'], shuffle=True, random_state=42)\n",
                "results = {}\n",
                "\n",
                "for model_name in MODEL_CONFIG['models']:\n",
                "    print(f'\\nTraining {model_name}...')\n",
                "    oof = np.zeros(len(X))\n",
                "    pred = np.zeros(len(X_test))\n",
                "    \n",
                "    for fold, (tr_idx, val_idx) in enumerate(kf.split(X)):\n",
                "        X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
                "        y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
                "        \n",
                "        if model_name == 'xgboost':\n",
                "            model = xgb.XGBRegressor(n_estimators=1000, max_depth=6, learning_rate=0.05,\n",
                "                                      random_state=42, verbosity=0)\n",
                "            model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
                "        elif model_name == 'lightgbm':\n",
                "            model = lgb.LGBMRegressor(n_estimators=1000, max_depth=6, learning_rate=0.05,\n",
                "                                       random_state=42, verbose=-1)\n",
                "            model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)],\n",
                "                     callbacks=[lgb.early_stopping(50, verbose=False)])\n",
                "        else:\n",
                "            model = CatBoostRegressor(iterations=1000, depth=6, learning_rate=0.05,\n",
                "                                       random_state=42, verbose=0)\n",
                "            model.fit(X_tr, y_tr, eval_set=(X_val, y_val), early_stopping_rounds=50)\n",
                "        \n",
                "        oof[val_idx] = model.predict(X_val)\n",
                "        pred += model.predict(X_test) / MODEL_CONFIG['n_folds']\n",
                "        print(f'  Fold {fold+1}: MAE = {mean_absolute_error(y_val, oof[val_idx]):.4f}')\n",
                "    \n",
                "    results[model_name] = {'oof': oof, 'pred': pred}\n",
                "    print(f'  OOF MAE: {mean_absolute_error(y, oof):.4f}')"
            ],
            "metadata": {
                "id": "train_models"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "---\n",
                "## Stage 5: Risk Factor Analysis"
            ],
            "metadata": {
                "id": "stage5"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "importance = pd.DataFrame({\n",
                "    'Feature': feature_cols,\n",
                "    'Importance': model.feature_importances_\n",
                "}).sort_values('Importance', ascending=False)\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.barh(importance['Feature'][:15], importance['Importance'][:15], color='steelblue')\n",
                "plt.xlabel('Importance')\n",
                "plt.title('Top 15 Risk Factors')\n",
                "plt.gca().invert_yaxis()\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ],
            "metadata": {
                "id": "feature_importance"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "---\n",
                "## Stage 6: Premium Calculation\n",
                "\n",
                "**Egyptian UHI Context:**\n",
                "\n",
                "| Category | Individual | Employer/State |\n",
                "|----------|------------|----------------|\n",
                "| Employee | 1% | 4% |\n",
                "| Non-working spouse | 3% | - |\n",
                "| Children (max 2) | 1% each | - |\n",
                "| Self-employed | 4% | - |\n",
                "| Pensioners | 1% | 2% |\n",
                "| Unable-to-pay | 0% | 5% |"
            ],
            "metadata": {
                "id": "stage6"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# ACTUARY DECISION: Pricing Parameters\n",
                "PRICING_CONFIG = {\n",
                "    'expense_loading': 0.25,\n",
                "    'profit_margin': 0.10,\n",
                "    'contingency_margin': 0.05,\n",
                "    'reinsurance_cost': 0.03,\n",
                "    'commission_rate': 0.15\n",
                "}\n",
                "\n",
                "total_loading = sum(PRICING_CONFIG.values())\n",
                "print(f'Total Loading: {total_loading*100:.0f}%')\n",
                "\n",
                "ensemble_pred = np.mean([results[m]['pred'] for m in results], axis=0)\n",
                "expected_loss = np.expm1(ensemble_pred)\n",
                "premium = expected_loss * (1 + total_loading)\n",
                "\n",
                "print(f'Mean Premium: ${np.mean(premium):,.0f}')\n",
                "print(f'Median Premium: ${np.median(premium):,.0f}')"
            ],
            "metadata": {
                "id": "calculate_premium"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "---\n",
                "## Stage 7: Output & Submission"
            ],
            "metadata": {
                "id": "stage7"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Create submission file\n",
                "submission = pd.DataFrame({\n",
                "    'ClaimNumber': test_clean['ClaimNumber'],\n",
                "    'UltimateIncurredClaimCost': np.maximum(expected_loss, 0)\n",
                "})\n",
                "\n",
                "submission.to_csv('submission.csv', index=False)\n",
                "print('Submission file created!')\n",
                "print(submission.head())"
            ],
            "metadata": {
                "id": "create_submission"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Submit to Kaggle\n",
                "!kaggle competitions submit -c actuarial-loss-estimation -f submission.csv -m \"Ensemble XGB+LGB+CatBoost\"\n",
                "print('\\nSubmission complete!')"
            ],
            "metadata": {
                "id": "submit_kaggle"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Download submission file locally\n",
                "from google.colab import files\n",
                "files.download('submission.csv')"
            ],
            "metadata": {
                "id": "download_submission"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "---\n",
                "## Summary\n",
                "\n",
                "| Stage | Objective | Decision Points |\n",
                "|-------|-----------|----------------|\n",
                "| 1. Data Collection | Gather historical data | Sources, period, granularity |\n",
                "| 2. Data Cleaning | Ensure quality | Imputation, outliers |\n",
                "| 3. EDA | Pattern analysis | Transformations |\n",
                "| 4. Loss Estimation | Predictive modeling | Model selection |\n",
                "| 5. Risk Factors | Driver identification | Factor validation |\n",
                "| 6. Premium Calculation | Apply loadings | Margins |\n",
                "| 7. Output & Submit | Kaggle submission | Final review |"
            ],
            "metadata": {
                "id": "summary"
            }
        }
    ]
}