{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ›ï¸ Ø£ØªÙ…ØªØ© Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§ÙƒØªÙˆØ§Ø±ÙŠØ© Ù„Ù„ØªØ³Ø¹ÙŠØ±\n",
        "## Actuarial Pricing Process Automation\n",
        "\n",
        "### ğŸ“Œ Ø§Ù„Ù‡Ø¯Ù:\n",
        "Ø´Ø±Ø­ ÙƒÙŠÙÙŠØ© Ø£ØªÙ…ØªØ© Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ³Ø¹ÙŠØ± Ø§Ù„Ø§ÙƒØªÙˆØ§Ø±ÙŠØ© Ù…Ø¹ ØªÙˆØ¶ÙŠØ­ **Ù†Ù‚Ø§Ø· Ø§Ù„ØªØ¯Ø®Ù„ ÙˆØ§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø±** ÙÙŠ ÙƒÙ„ Ù…Ø±Ø­Ù„Ø©\n",
        "\n",
        "### ğŸ”„ Ù…Ø±Ø§Ø­Ù„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©:\n",
        "```\n",
        "1. Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª â†’ 2. ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª â†’ 3. Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªÙƒØ´Ø§ÙÙŠ â†’ 4. ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø®Ø³Ø§Ø¦Ø±\n",
        "                                   â†“\n",
        "8. Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© â† 7. Ø§Ù„ØªØ³Ø¹ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ â† 6. Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£Ù‚Ø³Ø§Ø· â† 5. Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„Ø®Ø·Ø±\n",
        "```"
      ],
      "metadata": {"id": "intro"}
    },
    {
      "cell_type": "markdown",
      "source": ["## ğŸ“¦ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 0: Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ¦Ø©"],
      "metadata": {"id": "stage0"}
    },
    {
      "cell_type": "code",
      "source": [
        "# ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©\n",
        "!pip install -q xgboost lightgbm catboost shap kaggle"
      ],
      "metadata": {"id": "install"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ø¥Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "print('âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª')"
      ],
      "metadata": {"id": "imports"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## ğŸ“¥ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "\n",
        "### ğŸ¯ Ø§Ù„Ù‡Ø¯Ù:\n",
        "Ø¬Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©\n",
        "\n",
        "### ğŸ”§ Ù†Ù‚Ø·Ø© Ø§Ù„Ù‚Ø±Ø§Ø±:\n",
        "- Ù…Ø§ Ø§Ù„ÙØªØ±Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©ØŸ\n",
        "- Ù‡Ù„ Ù†Ø­ØªØ§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø®Ø§Ø±Ø¬ÙŠØ©ØŸ"
      ],
      "metadata": {"id": "stage1"}
    },
    {
      "cell_type": "code",
      "source": [
        "# === Ù†Ù‚Ø·Ø© Ù‚Ø±Ø§Ø±: Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ===\n",
        "DATA_CONFIG = {\n",
        "    'source': 'kaggle',\n",
        "    'period_years': 5,\n",
        "    'include_external': True\n",
        "}\n",
        "\n",
        "print(f'ğŸ“Š Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:')\n",
        "print(f'   - Ø§Ù„Ù…ØµØ¯Ø±: {DATA_CONFIG[\"source\"]}')\n",
        "print(f'   - Ø§Ù„ÙØªØ±Ø©: {DATA_CONFIG[\"period_years\"]} Ø³Ù†ÙˆØ§Øª')"
      ],
      "metadata": {"id": "data_config"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ø±ÙØ¹ Ù…Ù„Ù kaggle.json (Ù…Ù† Ø­Ø³Ø§Ø¨Ùƒ Ø¹Ù„Ù‰ Kaggle)\n",
        "from google.colab import files\n",
        "print('ğŸ“¤ Ø§Ø±ÙØ¹ Ù…Ù„Ù kaggle.json:')\n",
        "uploaded = files.upload()"
      ],
      "metadata": {"id": "upload_kaggle"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³Ø§Ø¨Ù‚Ø©\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c actuarial-loss-estimation\n",
        "!unzip -q -o actuarial-loss-estimation.zip\n",
        "print('âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª')"
      ],
      "metadata": {"id": "download_data"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "\n",
        "print(f'ğŸ“ˆ Ø­Ø¬Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {train.shape}')\n",
        "print(f'ğŸ“‰ Ø­Ø¬Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {test.shape}')\n",
        "train.head()"
      ],
      "metadata": {"id": "load_data"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## ğŸ§¹ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "\n",
        "### ğŸ”§ Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚Ø±Ø§Ø±:\n",
        "- ÙƒÙŠÙ Ù†ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©ØŸ\n",
        "- Ù‡Ù„ Ù†Ø­Ø°Ù Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªØ·Ø±ÙØ©ØŸ"
      ],
      "metadata": {"id": "stage2"}
    },
    {
      "cell_type": "code",
      "source": [
        "# ØªØ­Ù„ÙŠÙ„ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "print('ğŸ“‹ ØªÙ‚Ø±ÙŠØ± Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:')\n",
        "print(f'Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø³Ø¬Ù„Ø§Øª: {len(train):,}')\n",
        "\n",
        "missing = train.isnull().sum()\n",
        "missing_pct = (missing / len(train) * 100).round(2)\n",
        "missing_report = pd.DataFrame({'Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙÙ‚ÙˆØ¯': missing, 'Ø§Ù„Ù†Ø³Ø¨Ø© %': missing_pct})\n",
        "missing_report[missing_report['Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙÙ‚ÙˆØ¯'] > 0]"
      ],
      "metadata": {"id": "data_quality"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Ù†Ù‚Ø·Ø© Ù‚Ø±Ø§Ø±: Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© ===\n",
        "MISSING_STRATEGY = {\n",
        "    'numeric': 'median',       # median, mean, zero\n",
        "    'categorical': 'mode',     # mode, 'MISSING'\n",
        "    'threshold_drop': 0.5      # Ø­Ø°Ù Ø£Ø¹Ù…Ø¯Ø© > 50% Ù…ÙÙ‚ÙˆØ¯\n",
        "}\n",
        "\n",
        "print('ğŸ”§ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©:')\n",
        "for k, v in MISSING_STRATEGY.items():\n",
        "    print(f'   - {k}: {v}')"
      ],
      "metadata": {"id": "missing_config"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "def clean_data(df, config):\n",
        "    df = df.copy()\n",
        "    \n",
        "    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ©\n",
        "    for col in df.select_dtypes(include=[np.number]).columns:\n",
        "        if df[col].isnull().any():\n",
        "            if config['numeric'] == 'median':\n",
        "                df[col] = df[col].fillna(df[col].median())\n",
        "            elif config['numeric'] == 'mean':\n",
        "                df[col] = df[col].fillna(df[col].mean())\n",
        "    \n",
        "    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ÙØ¦ÙˆÙŠØ©\n",
        "    for col in df.select_dtypes(include=['object']).columns:\n",
        "        if df[col].isnull().any():\n",
        "            df[col] = df[col].fillna('MISSING')\n",
        "    \n",
        "    return df\n",
        "\n",
        "train_clean = clean_data(train, MISSING_STRATEGY)\n",
        "test_clean = clean_data(test, MISSING_STRATEGY)\n",
        "print('âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª')"
      ],
      "metadata": {"id": "clean_data"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## ğŸ“Š Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªÙƒØ´Ø§ÙÙŠ\n",
        "\n",
        "### ğŸ”§ Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚Ø±Ø§Ø±:\n",
        "- Ù‡Ù„ Ø§Ù„ØªÙˆØ²ÙŠØ¹ ÙŠØ­ØªØ§Ø¬ ØªØ­ÙˆÙŠÙ„ØŸ\n",
        "- Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ø¤Ø«Ø±Ø©ØŸ"
      ],
      "metadata": {"id": "stage3"}
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET = 'UltimateIncurredClaimCost'\n",
        "\n",
        "# ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "axes[0].hist(train_clean[TARGET], bins=50, color='steelblue', edgecolor='white')\n",
        "axes[0].set_title('Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£ØµÙ„ÙŠ', fontsize=12)\n",
        "\n",
        "axes[1].hist(np.log1p(train_clean[TARGET]), bins=50, color='coral', edgecolor='white')\n",
        "axes[1].set_title('Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù„ÙˆØºØ§Ø±ÙŠØªÙ…ÙŠ', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {"id": "eda_target"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Ù†Ù‚Ø·Ø© Ù‚Ø±Ø§Ø±: ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù ===\n",
        "TARGET_TRANSFORM = 'log'  # 'none', 'log', 'sqrt'\n",
        "\n",
        "print(f'ğŸ¯ Ù‚Ø±Ø§Ø±: Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªØ­ÙˆÙŠÙ„ {TARGET_TRANSFORM}')\n",
        "\n",
        "if TARGET_TRANSFORM == 'log':\n",
        "    y = np.log1p(train_clean[TARGET])\n",
        "else:\n",
        "    y = train_clean[TARGET]"
      ],
      "metadata": {"id": "target_transform"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## ğŸ“ˆ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 4: ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø®Ø³Ø§Ø¦Ø± (Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬)\n",
        "\n",
        "### ğŸ”§ Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚Ø±Ø§Ø±:\n",
        "- Ø£ÙŠ Ù†Ù…ÙˆØ°Ø¬ Ù†Ø³ØªØ®Ø¯Ù…ØŸ\n",
        "- Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ù…Ø«Ù„Ù‰ØŸ"
      ],
      "metadata": {"id": "stage4"}
    },
    {
      "cell_type": "code",
      "source": [
        "# ØªØ­Ø¶ÙŠØ± Ø§Ù„Ù…ÙŠØ²Ø§Øª\n",
        "EXCLUDE_COLS = [TARGET, 'ClaimNumber', 'ClaimDescription', 'AccidentDescription',\n",
        "                'DateTimeOfAccident', 'DateReported', 'DateOfBirth']\n",
        "\n",
        "feature_cols = [c for c in train_clean.columns if c not in EXCLUDE_COLS]\n",
        "\n",
        "# ØªØ±Ù…ÙŠØ² Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„ÙØ¦ÙˆÙŠØ©\n",
        "for col in train_clean[feature_cols].select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    all_vals = pd.concat([train_clean[col], test_clean[col]]).astype(str).unique()\n",
        "    le.fit(all_vals)\n",
        "    train_clean[col] = le.transform(train_clean[col].astype(str))\n",
        "    test_clean[col] = le.transform(test_clean[col].astype(str))\n",
        "\n",
        "X = train_clean[feature_cols].fillna(-999)\n",
        "X_test = test_clean[feature_cols].fillna(-999)\n",
        "\n",
        "print(f'âœ… ØªÙ… ØªØ­Ø¶ÙŠØ± {len(feature_cols)} Ù…ÙŠØ²Ø©')"
      ],
      "metadata": {"id": "prepare_features"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Ù†Ù‚Ø·Ø© Ù‚Ø±Ø§Ø±: Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ===\n",
        "MODEL_CONFIG = {\n",
        "    'models': ['xgboost', 'lightgbm', 'catboost'],\n",
        "    'n_folds': 5,\n",
        "    'ensemble_method': 'average',\n",
        "    'hyperparams': {\n",
        "        'max_depth': 6,\n",
        "        'learning_rate': 0.05,\n",
        "        'n_estimators': 1000\n",
        "    }\n",
        "}\n",
        "\n",
        "print('ğŸ¤– Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ù…Ø°Ø¬Ø©:')\n",
        "print(f'   - Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {MODEL_CONFIG[\"models\"]}')\n",
        "print(f'   - Folds: {MODEL_CONFIG[\"n_folds\"]}')\n",
        "print(f'   - Ø§Ù„Ø¯Ù…Ø¬: {MODEL_CONFIG[\"ensemble_method\"]}')"
      ],
      "metadata": {"id": "model_config"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬\n",
        "kf = KFold(n_splits=MODEL_CONFIG['n_folds'], shuffle=True, random_state=42)\n",
        "results = {}\n",
        "\n",
        "for model_name in MODEL_CONFIG['models']:\n",
        "    print(f'\\nğŸš€ ØªØ¯Ø±ÙŠØ¨ {model_name}...')\n",
        "    oof = np.zeros(len(X))\n",
        "    pred = np.zeros(len(X_test))\n",
        "    \n",
        "    for fold, (tr_idx, val_idx) in enumerate(kf.split(X)):\n",
        "        X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
        "        y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
        "        \n",
        "        if model_name == 'xgboost':\n",
        "            model = xgb.XGBRegressor(n_estimators=1000, max_depth=6, learning_rate=0.05,\n",
        "                                      random_state=42, verbosity=0)\n",
        "            model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "        elif model_name == 'lightgbm':\n",
        "            model = lgb.LGBMRegressor(n_estimators=1000, max_depth=6, learning_rate=0.05,\n",
        "                                       random_state=42, verbose=-1)\n",
        "            model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)],\n",
        "                     callbacks=[lgb.early_stopping(50, verbose=False)])\n",
        "        else:\n",
        "            model = CatBoostRegressor(iterations=1000, depth=6, learning_rate=0.05,\n",
        "                                       random_state=42, verbose=0)\n",
        "            model.fit(X_tr, y_tr, eval_set=(X_val, y_val), early_stopping_rounds=50)\n",
        "        \n",
        "        oof[val_idx] = model.predict(X_val)\n",
        "        pred += model.predict(X_test) / MODEL_CONFIG['n_folds']\n",
        "        print(f'   Fold {fold+1}: MAE = {mean_absolute_error(y_val, oof[val_idx]):.4f}')\n",
        "    \n",
        "    results[model_name] = {'oof': oof, 'pred': pred}\n",
        "    print(f'   âœ… OOF MAE: {mean_absolute_error(y, oof):.4f}')"
      ],
      "metadata": {"id": "train_models"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## âš–ï¸ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 5: ØªØ­Ù„ÙŠÙ„ Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„Ø®Ø·Ø±\n",
        "\n",
        "### ğŸ”§ Ù†Ù‚Ø·Ø© Ø§Ù„Ù‚Ø±Ø§Ø±:\n",
        "- Ù‡Ù„ Ø§Ù„Ø¹ÙˆØ§Ù…Ù„ Ù…Ù†Ø·Ù‚ÙŠØ©ØŸ\n",
        "- Ù‡Ù„ Ù†Ø­ØªØ§Ø¬ ØªØ¹Ø¯ÙŠÙ„Ø§ØªØŸ"
      ],
      "metadata": {"id": "stage5"}
    },
    {
      "cell_type": "code",
      "source": [
        "# Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª\n",
        "importance = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'importance': model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(importance['feature'][:15], importance['importance'][:15], color='steelblue')\n",
        "plt.xlabel('Ø§Ù„Ø£Ù‡Ù…ÙŠØ©')\n",
        "plt.title('Ø£Ù‡Ù… 15 Ø¹Ø§Ù…Ù„ Ø®Ø·Ø±')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {"id": "feature_importance"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## ğŸ’° Ø§Ù„Ù…Ø±Ø­Ù„Ø© 6: Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£Ù‚Ø³Ø§Ø·\n",
        "\n",
        "### ğŸ”§ Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚Ø±Ø§Ø±:\n",
        "- Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„ØŸ\n",
        "- Ù‡Ø§Ù…Ø´ Ø§Ù„Ø±Ø¨Ø­ØŸ"
      ],
      "metadata": {"id": "stage6"}
    },
    {
      "cell_type": "code",
      "source": [
        "# === Ù†Ù‚Ø·Ø© Ù‚Ø±Ø§Ø±: Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„ØªØ³Ø¹ÙŠØ± ===\n",
        "PRICING_CONFIG = {\n",
        "    'expense_loading': 0.25,      # Ø§Ù„Ù…ØµØ§Ø±ÙŠÙ Ø§Ù„Ø¥Ø¯Ø§Ø±ÙŠØ©\n",
        "    'profit_margin': 0.10,        # Ù‡Ø§Ù…Ø´ Ø§Ù„Ø±Ø¨Ø­\n",
        "    'contingency_margin': 0.05,   # Ù‡Ø§Ù…Ø´ Ø§Ù„Ø·ÙˆØ§Ø±Ø¦\n",
        "    'reinsurance_cost': 0.03,     # Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ£Ù…ÙŠÙ†\n",
        "    'commission_rate': 0.15       # Ø§Ù„Ø¹Ù…ÙˆÙ„Ø§Øª\n",
        "}\n",
        "\n",
        "print('ğŸ’° Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„ØªØ³Ø¹ÙŠØ±:')\n",
        "for k, v in PRICING_CONFIG.items():\n",
        "    print(f'   - {k}: {v*100:.0f}%')\n",
        "\n",
        "total_loading = sum(PRICING_CONFIG.values())\n",
        "print(f'\\n   ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„: {total_loading*100:.0f}%')"
      ],
      "metadata": {"id": "pricing_config"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£Ù‚Ø³Ø§Ø·\n",
        "ensemble_pred = np.mean([results[m]['pred'] for m in results], axis=0)\n",
        "expected_loss = np.expm1(ensemble_pred)  # ØªØ­ÙˆÙŠÙ„ Ø¹ÙƒØ³ÙŠ\n",
        "\n",
        "premium = expected_loss * (1 + total_loading)\n",
        "\n",
        "print(f'ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ù‚Ø³Ø§Ø·:')\n",
        "print(f'   - Ø§Ù„Ù…ØªÙˆØ³Ø·: ${np.mean(premium):,.0f}')\n",
        "print(f'   - Ø§Ù„ÙˆØ³ÙŠØ·: ${np.median(premium):,.0f}')"
      ],
      "metadata": {"id": "calculate_premium"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## âœ… Ø§Ù„Ù…Ø±Ø­Ù„Ø© 7: Ø§Ù„ØªØ³Ø¹ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ\n",
        "\n",
        "### ğŸ”§ Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚Ø±Ø§Ø±:\n",
        "- ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ø§Ù„Ø³ÙˆÙ‚ØŸ\n",
        "- Ø§Ù„Ø­Ø¯ÙˆØ¯ Ø§Ù„Ù‚ØµÙˆÙ‰ ÙˆØ§Ù„Ø¯Ù†ÙŠØ§ØŸ"
      ],
      "metadata": {"id": "stage7"}
    },
    {
      "cell_type": "code",
      "source": [
        "# === Ù†Ù‚Ø·Ø© Ù‚Ø±Ø§Ø±: Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© ===\n",
        "FINAL_CONFIG = {\n",
        "    'market_adjustment': 0.95,    # Ø®ØµÙ… 5% Ù„Ù„ØªÙ†Ø§ÙØ³ÙŠØ©\n",
        "    'min_premium': 100,\n",
        "    'max_premium': 1000000\n",
        "}\n",
        "\n",
        "final_premium = premium * FINAL_CONFIG['market_adjustment']\n",
        "final_premium = np.clip(final_premium, FINAL_CONFIG['min_premium'], FINAL_CONFIG['max_premium'])\n",
        "\n",
        "print('âœ… Ø§Ù„Ø£Ù‚Ø³Ø§Ø· Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:')\n",
        "print(f'   - Ø§Ù„Ù…ØªÙˆØ³Ø·: ${np.mean(final_premium):,.0f}')\n",
        "print(f'   - Ø§Ù„ÙˆØ³ÙŠØ·: ${np.median(final_premium):,.0f}')"
      ],
      "metadata": {"id": "final_pricing"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["---\n", "## ğŸ“¤ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 8: Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø§Ù„ØªÙ‚Ø¯ÙŠÙ…"],
      "metadata": {"id": "stage8"}
    },
    {
      "cell_type": "code",
      "source": [
        "# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø§Ù„ØªÙ‚Ø¯ÙŠÙ…\n",
        "submission = pd.DataFrame({\n",
        "    'ClaimNumber': test_clean['ClaimNumber'],\n",
        "    'UltimateIncurredClaimCost': np.maximum(expected_loss, 0)\n",
        "})\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print('âœ… ØªÙ… Ø­ÙØ¸: submission.csv')\n",
        "submission.head()"
      ],
      "metadata": {"id": "create_submission"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù\n",
        "from google.colab import files\n",
        "files.download('submission.csv')\n",
        "print('ğŸ“¥ ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù')"
      ],
      "metadata": {"id": "download_submission"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## ğŸ“‹ Ù…Ù„Ø®Øµ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§ÙƒØªÙˆØ§Ø±ÙŠØ©\n",
        "\n",
        "| Ø§Ù„Ù…Ø±Ø­Ù„Ø© | Ø§Ù„Ù‡Ø¯Ù | Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚Ø±Ø§Ø± |\n",
        "|---------|-------|-------------|\n",
        "| 1. Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª | Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© | Ø§Ù„Ù…ØµØ§Ø¯Ø±ØŒ Ø§Ù„ÙØªØ±Ø© |\n",
        "| 2. ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª | Ø¶Ù…Ø§Ù† Ø§Ù„Ø¬ÙˆØ¯Ø© | Ø§Ù„Ù…ÙÙ‚ÙˆØ¯ØŒ Ø§Ù„Ù…ØªØ·Ø±Ù |\n",
        "| 3. Ø§Ù„ØªØ­Ù„ÙŠÙ„ | ÙÙ‡Ù… Ø§Ù„Ø£Ù†Ù…Ø§Ø· | Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª |\n",
        "| 4. ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø®Ø³Ø§Ø¦Ø± | Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ | Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ØŒ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª |\n",
        "| 5. Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„Ø®Ø·Ø± | ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø¤Ø«Ø±Ø§Øª | Ø§Ù„Ø£ÙˆØ²Ø§Ù† |\n",
        "| 6. Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£Ù‚Ø³Ø§Ø· | Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ù„Ø£Ù‚Ø³Ø§Ø· | Ø§Ù„ØªØ­Ù…ÙŠÙ„Ø§Øª |\n",
        "| 7. Ø§Ù„ØªØ³Ø¹ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ | Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ | ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ø§Ù„Ø³ÙˆÙ‚ |\n",
        "\n",
        "### ğŸ‰ ØªÙ… Ø¨Ù†Ø§Ø¡ Ù†Ø¸Ø§Ù… Ø£ØªÙ…ØªØ© Ù…ØªÙƒØ§Ù…Ù„ Ù„Ù„ØªØ³Ø¹ÙŠØ± Ø§Ù„Ø§ÙƒØªÙˆØ§Ø±ÙŠ!"
      ],
      "metadata": {"id": "summary"}
    }
  ]
}
